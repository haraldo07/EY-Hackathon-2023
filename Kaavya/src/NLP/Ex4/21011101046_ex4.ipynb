{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce778b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "963756c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
       "0           0      3            0                   0        3      2   \n",
       "1           1      3            0                   3        0      1   \n",
       "2           2      3            0                   3        0      1   \n",
       "3           3      3            0                   2        1      1   \n",
       "4           4      6            0                   6        0      1   \n",
       "\n",
       "                                               tweet  \n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
       "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
       "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
       "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
       "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('labeled_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67d08b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24783 entries, 0 to 24782\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   Unnamed: 0          24783 non-null  int64 \n",
      " 1   count               24783 non-null  int64 \n",
      " 2   hate_speech         24783 non-null  int64 \n",
      " 3   offensive_language  24783 non-null  int64 \n",
      " 4   neither             24783 non-null  int64 \n",
      " 5   class               24783 non-null  int64 \n",
      " 6   tweet               24783 non-null  object\n",
      "dtypes: int64(6), object(1)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc0cde1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.chunk import ne_chunk\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec7a1a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bf2a580",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_text(tokens):\n",
    "    return \" \".join([token for token in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a5b3fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>! ! ! RT @ mayasolovely : As a woman you shoul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>! ! ! ! ! RT @ mleew17 : boy dats cold ... tyg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>! ! ! ! ! ! ! RT @ UrKindOfBrand Dawg ! ! ! ! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>! ! ! ! ! ! ! ! ! RT @ C_G_Anderson : @ viva_b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>! ! ! ! ! ! ! ! ! ! ! ! ! RT @ ShenikaRoberts ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
       "0           0      3            0                   0        3      2   \n",
       "1           1      3            0                   3        0      1   \n",
       "2           2      3            0                   3        0      1   \n",
       "3           3      3            0                   2        1      1   \n",
       "4           4      6            0                   6        0      1   \n",
       "\n",
       "                                               tweet  \n",
       "0  ! ! ! RT @ mayasolovely : As a woman you shoul...  \n",
       "1  ! ! ! ! ! RT @ mleew17 : boy dats cold ... tyg...  \n",
       "2  ! ! ! ! ! ! ! RT @ UrKindOfBrand Dawg ! ! ! ! ...  \n",
       "3  ! ! ! ! ! ! ! ! ! RT @ C_G_Anderson : @ viva_b...  \n",
       "4  ! ! ! ! ! ! ! ! ! ! ! ! ! RT @ ShenikaRoberts ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet'] = df['tweet'].apply(word_tokenize)\n",
    "df['tweet'] = df['tweet'].apply(concat_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e822e199",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(text):\n",
    "    removed_text = \"\"\n",
    "    for char in str(text.lower()):\n",
    "        if char not in string.punctuation:\n",
    "            removed_text+=char\n",
    "    return removed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18bf1685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>rt  mayasolovely  as a woman you should nt ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>rt  mleew17  boy dats cold  tyga dwn bad ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>rt  urkindofbrand dawg     rt  80sbaby4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>rt  cganderson   vivabased she look l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>rt  shenikaroberts  the shit you ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
       "0           0      3            0                   0        3      2   \n",
       "1           1      3            0                   3        0      1   \n",
       "2           2      3            0                   3        0      1   \n",
       "3           3      3            0                   2        1      1   \n",
       "4           4      6            0                   6        0      1   \n",
       "\n",
       "                                               tweet  \n",
       "0     rt  mayasolovely  as a woman you should nt ...  \n",
       "1       rt  mleew17  boy dats cold  tyga dwn bad ...  \n",
       "2         rt  urkindofbrand dawg     rt  80sbaby4...  \n",
       "3           rt  cganderson   vivabased she look l...  \n",
       "4               rt  shenikaroberts  the shit you ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet'] = df['tweet'].apply(remove_punc)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a602bdb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>[rt, mayasolovely, as, a, woman, you, should, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[rt, mleew17, boy, dats, cold, tyga, dwn, bad,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[rt, urkindofbrand, dawg, rt, 80sbaby4life, yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[rt, cganderson, vivabased, she, look, like, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[rt, shenikaroberts, the, shit, you, hear, abo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
       "0           0      3            0                   0        3      2   \n",
       "1           1      3            0                   3        0      1   \n",
       "2           2      3            0                   3        0      1   \n",
       "3           3      3            0                   2        1      1   \n",
       "4           4      6            0                   6        0      1   \n",
       "\n",
       "                                               tweet  \n",
       "0  [rt, mayasolovely, as, a, woman, you, should, ...  \n",
       "1  [rt, mleew17, boy, dats, cold, tyga, dwn, bad,...  \n",
       "2  [rt, urkindofbrand, dawg, rt, 80sbaby4life, yo...  \n",
       "3  [rt, cganderson, vivabased, she, look, like, a...  \n",
       "4  [rt, shenikaroberts, the, shit, you, hear, abo...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet'] = df['tweet'].apply(word_tokenize)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1fa7379",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rem_stop(tokens):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [token for token in tokens if token.lower() not in stop_words]\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "000e6a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>[rt, mayasolovely, woman, nt, complain, cleani...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[rt, mleew17, boy, dats, cold, tyga, dwn, bad,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[rt, urkindofbrand, dawg, rt, 80sbaby4life, ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[rt, cganderson, vivabased, look, like, tranny]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[rt, shenikaroberts, shit, hear, might, true, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
       "0           0      3            0                   0        3      2   \n",
       "1           1      3            0                   3        0      1   \n",
       "2           2      3            0                   3        0      1   \n",
       "3           3      3            0                   2        1      1   \n",
       "4           4      6            0                   6        0      1   \n",
       "\n",
       "                                               tweet  \n",
       "0  [rt, mayasolovely, woman, nt, complain, cleani...  \n",
       "1  [rt, mleew17, boy, dats, cold, tyga, dwn, bad,...  \n",
       "2  [rt, urkindofbrand, dawg, rt, 80sbaby4life, ev...  \n",
       "3    [rt, cganderson, vivabased, look, like, tranny]  \n",
       "4  [rt, shenikaroberts, shit, hear, might, true, ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet']= df['tweet'].apply(rem_stop)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2693ece5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemma_tokens(tokens):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a711448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>[rt, mayasolovely, woman, nt, complain, cleani...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[rt, mleew17, boy, dat, cold, tyga, dwn, bad, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[rt, urkindofbrand, dawg, rt, 80sbaby4life, ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[rt, cganderson, vivabased, look, like, tranny]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[rt, shenikaroberts, shit, hear, might, true, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
       "0           0      3            0                   0        3      2   \n",
       "1           1      3            0                   3        0      1   \n",
       "2           2      3            0                   3        0      1   \n",
       "3           3      3            0                   2        1      1   \n",
       "4           4      6            0                   6        0      1   \n",
       "\n",
       "                                               tweet  \n",
       "0  [rt, mayasolovely, woman, nt, complain, cleani...  \n",
       "1  [rt, mleew17, boy, dat, cold, tyga, dwn, bad, ...  \n",
       "2  [rt, urkindofbrand, dawg, rt, 80sbaby4life, ev...  \n",
       "3    [rt, cganderson, vivabased, look, like, tranny]  \n",
       "4  [rt, shenikaroberts, shit, hear, might, true, ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet'] = df['tweet'].apply(lemma_tokens)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9bb1ea43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "      <th>pre_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>[rt, mayasolovely, woman, nt, complain, cleani...</td>\n",
       "      <td>rt mayasolovely woman nt complain cleaning hou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[rt, mleew17, boy, dat, cold, tyga, dwn, bad, ...</td>\n",
       "      <td>rt mleew17 boy dat cold tyga dwn bad cuffin da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[rt, urkindofbrand, dawg, rt, 80sbaby4life, ev...</td>\n",
       "      <td>rt urkindofbrand dawg rt 80sbaby4life ever fuc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[rt, cganderson, vivabased, look, like, tranny]</td>\n",
       "      <td>rt cganderson vivabased look like tranny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[rt, shenikaroberts, shit, hear, might, true, ...</td>\n",
       "      <td>rt shenikaroberts shit hear might true might f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
       "0           0      3            0                   0        3      2   \n",
       "1           1      3            0                   3        0      1   \n",
       "2           2      3            0                   3        0      1   \n",
       "3           3      3            0                   2        1      1   \n",
       "4           4      6            0                   6        0      1   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  [rt, mayasolovely, woman, nt, complain, cleani...   \n",
       "1  [rt, mleew17, boy, dat, cold, tyga, dwn, bad, ...   \n",
       "2  [rt, urkindofbrand, dawg, rt, 80sbaby4life, ev...   \n",
       "3    [rt, cganderson, vivabased, look, like, tranny]   \n",
       "4  [rt, shenikaroberts, shit, hear, might, true, ...   \n",
       "\n",
       "                                           pre_tweet  \n",
       "0  rt mayasolovely woman nt complain cleaning hou...  \n",
       "1  rt mleew17 boy dat cold tyga dwn bad cuffin da...  \n",
       "2  rt urkindofbrand dawg rt 80sbaby4life ever fuc...  \n",
       "3           rt cganderson vivabased look like tranny  \n",
       "4  rt shenikaroberts shit hear might true might f...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pre_tweet'] = df['tweet'].apply(concat_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1356099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>pre_tweet</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[rt, mayasolovely, woman, nt, complain, cleani...</td>\n",
       "      <td>rt mayasolovely woman nt complain cleaning hou...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[rt, mleew17, boy, dat, cold, tyga, dwn, bad, ...</td>\n",
       "      <td>rt mleew17 boy dat cold tyga dwn bad cuffin da...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[rt, urkindofbrand, dawg, rt, 80sbaby4life, ev...</td>\n",
       "      <td>rt urkindofbrand dawg rt 80sbaby4life ever fuc...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[rt, cganderson, vivabased, look, like, tranny]</td>\n",
       "      <td>rt cganderson vivabased look like tranny</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[rt, shenikaroberts, shit, hear, might, true, ...</td>\n",
       "      <td>rt shenikaroberts shit hear might true might f...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  \\\n",
       "0  [rt, mayasolovely, woman, nt, complain, cleani...   \n",
       "1  [rt, mleew17, boy, dat, cold, tyga, dwn, bad, ...   \n",
       "2  [rt, urkindofbrand, dawg, rt, 80sbaby4life, ev...   \n",
       "3    [rt, cganderson, vivabased, look, like, tranny]   \n",
       "4  [rt, shenikaroberts, shit, hear, might, true, ...   \n",
       "\n",
       "                                           pre_tweet  count  hate_speech  \\\n",
       "0  rt mayasolovely woman nt complain cleaning hou...      3            0   \n",
       "1  rt mleew17 boy dat cold tyga dwn bad cuffin da...      3            0   \n",
       "2  rt urkindofbrand dawg rt 80sbaby4life ever fuc...      3            0   \n",
       "3           rt cganderson vivabased look like tranny      3            0   \n",
       "4  rt shenikaroberts shit hear might true might f...      6            0   \n",
       "\n",
       "   offensive_language  neither  class  \n",
       "0                   0        3      2  \n",
       "1                   3        0      1  \n",
       "2                   3        0      1  \n",
       "3                   2        1      1  \n",
       "4                   6        0      1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.iloc[:,[6,7,1,2,3,4,5]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dc10b7",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15cd7c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\miniconda3\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "sg = Word2Vec(df['pre_tweet'].values.tolist(), vector_size=150, window=5, min_count=2, sg=1)\n",
    "vocab = sg.wv.index_to_key\n",
    "def get_mean_vector(model, sentence):\n",
    "    words = [word for word in sentence if word in vocab]\n",
    "    if len(words) >= 1:\n",
    "        return np.mean(model.wv[words], axis=0)\n",
    "    return np.zeros((150,))\n",
    "sg_vector = []\n",
    "for sentence in df['pre_tweet'].values.tolist():\n",
    "    sg_vector.append(get_mean_vector(sg, sentence))\n",
    "sg_vector = np.array(sg_vector)\n",
    "sg_df= pd.DataFrame(sg_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b130a827",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xw2v = pd.concat([sg_df, df.iloc[:,2:-1]], axis=1, join='inner').values\n",
    "Yw2v= df.iloc[:,-1]\n",
    "x_trainw2v, x_testw2v, y_trainw2v, y_testw2v = train_test_split(Xw2v, Yw2v,random_state=42, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "beb2562c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nbw2v = GaussianNB()\n",
    "nbw2v.fit(x_trainw2v,y_trainw2v)\n",
    "\n",
    "y_predw2v= nbw2v.predict(x_testw2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "71246aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5468043899289864"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_testw2v,y_predw2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fc9384",
   "metadata": {},
   "source": [
    "# FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "632933d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "ft=FastText(df['pre_tweet'].values.tolist(),vector_size=100,window=5,min_count=1,workers=4)\n",
    "def get_mean_vector(model, sentence):\n",
    "    words = [word for word in sentence if word in vocab]\n",
    "    if len(words) >= 1:\n",
    "        return np.mean(model.wv[words], axis=0)\n",
    "    return np.zeros((100,))\n",
    "ft_vector = []\n",
    "for sentence in df['pre_tweet'].values.tolist():\n",
    "    ft_vector.append(get_mean_vector(ft, sentence))\n",
    "ft_vector = np.array(ft_vector)\n",
    "ft_df= pd.DataFrame(ft_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "afd3a3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xft = pd.concat([ft_df, df.iloc[:,2:-1]], axis=1, join='inner').values\n",
    "Yft= df.iloc[:,-1]\n",
    "x_trainft, x_testft, y_trainft, y_testft = train_test_split(Xft, Yft,random_state=42, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d8e527db-b640-46f3-bb2e-2fb31ee5ba0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nbft = GaussianNB()\n",
    "nbft.fit(x_trainft,y_trainft)\n",
    "\n",
    "y_predft= nbft.predict(x_testft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d421062-63e2-4164-bd30-8eab58b48997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6826985151710782"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_testft,y_predft)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb39425-f29f-4097-9803-39b39eabf485",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c6953943-3ed8-402b-a82b-ac251a3e14e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df['pre_tweet'])\n",
    "tokenized_text = tokenizer.texts_to_sequences(df['pre_tweet'])\n",
    "\n",
    "max_seq_length = max(len(seq) for seq in tokenized_text)\n",
    "padded_text = pad_sequences(tokenized_text, maxlen=max_seq_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "51f46401-bda4-4565-9634-f4493426934d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_traincnn, x_testcnn, y_traincnn, y_testcnn = train_test_split(padded_text, df['class'], test_size=0.25, random_state=42)\n",
    "x_traincnn = np.expand_dims(x_traincnn, axis=-1)\n",
    "x_testcnn = np.expand_dims(x_testcnn, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "33b2ab40-d3ad-4115-a560-5121812e2f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "581/581 [==============================] - 2s 1ms/step - loss: 6586.6890\n",
      "Epoch 2/100\n",
      "581/581 [==============================] - 1s 1ms/step - loss: 2.0892\n",
      "Epoch 3/100\n",
      "581/581 [==============================] - 1s 1ms/step - loss: 1.3927\n",
      "Epoch 4/100\n",
      "581/581 [==============================] - 1s 1ms/step - loss: 1.2197\n",
      "Epoch 5/100\n",
      "581/581 [==============================] - 1s 1ms/step - loss: 1.0780\n",
      "Epoch 6/100\n",
      "581/581 [==============================] - 1s 2ms/step - loss: 0.9361\n",
      "Epoch 7/100\n",
      "581/581 [==============================] - 1s 1ms/step - loss: 0.7962\n",
      "Epoch 8/100\n",
      "581/581 [==============================] - 1s 1ms/step - loss: 0.6639\n",
      "Epoch 9/100\n",
      "581/581 [==============================] - 1s 2ms/step - loss: 0.5455\n",
      "Epoch 10/100\n",
      "581/581 [==============================] - 1s 2ms/step - loss: 0.4454\n",
      "Epoch 11/100\n",
      "581/581 [==============================] - 1s 2ms/step - loss: 0.3659\n",
      "Epoch 12/100\n",
      "581/581 [==============================] - 1s 1ms/step - loss: 0.3068\n",
      "Epoch 13/100\n",
      "581/581 [==============================] - 1s 2ms/step - loss: 0.2660\n",
      "Epoch 14/100\n",
      "581/581 [==============================] - 1s 1ms/step - loss: 0.2401\n",
      "Epoch 15/100\n",
      "581/581 [==============================] - 1s 2ms/step - loss: 0.2254\n",
      "Epoch 16/100\n",
      "581/581 [==============================] - 1s 1ms/step - loss: 0.2180\n",
      "Epoch 17/100\n",
      "581/581 [==============================] - 1s 2ms/step - loss: 0.2149\n",
      "Epoch 18/100\n",
      "581/581 [==============================] - 1s 2ms/step - loss: 0.2137\n",
      "Epoch 19/100\n",
      "581/581 [==============================] - 1s 2ms/step - loss: 0.2134\n",
      "Epoch 20/100\n",
      "581/581 [==============================] - 1s 2ms/step - loss: 0.2133\n",
      "Epoch 21/100\n",
      "581/581 [==============================] - 1s 2ms/step - loss: 0.2133\n",
      "Epoch 22/100\n",
      "581/581 [==============================] - 1s 2ms/step - loss: 0.2133\n",
      "Epoch 23/100\n",
      "581/581 [==============================] - 1s 2ms/step - loss: 0.2133\n",
      "Epoch 24/100\n",
      "581/581 [==============================] - 1s 2ms/step - loss: 0.2617\n",
      "Epoch 25/100\n",
      "581/581 [==============================] - 1s 2ms/step - loss: 0.2134\n",
      "Epoch 26/100\n",
      "581/581 [==============================] - 1s 2ms/step - loss: 0.2133\n",
      "Epoch 27/100\n",
      "581/581 [==============================] - 1s 2ms/step - loss: 0.2133\n",
      "Epoch 28/100\n",
      "581/581 [==============================] - 1s 2ms/step - loss: 0.2134\n",
      "Epoch 29/100\n",
      "581/581 [==============================] - 1s 2ms/step - loss: 0.2133\n",
      "Epoch 30/100\n",
      "581/581 [==============================] - 1s 2ms/step - loss: 0.2134\n",
      "Epoch 31/100\n",
      "581/581 [==============================] - 1s 2ms/step - loss: 0.2133\n",
      "Epoch 32/100\n",
      "581/581 [==============================] - 1s 2ms/step - loss: 0.2133\n",
      "Epoch 33/100\n",
      "581/581 [==============================] - 1s 2ms/step - loss: 0.2134\n",
      "Epoch 34/100\n",
      "581/581 [==============================] - 1s 2ms/step - loss: 0.2134\n",
      "Epoch 35/100\n",
      "581/581 [==============================] - 1s 2ms/step - loss: 0.2133\n",
      "Epoch 36/100\n",
      "581/581 [==============================] - 1s 2ms/step - loss: 0.2133\n",
      "Epoch 37/100\n",
      "581/581 [==============================] - 1s 2ms/step - loss: 0.2134\n",
      "Epoch 38/100\n",
      "581/581 [==============================] - 1s 2ms/step - loss: 0.2133\n",
      "Epoch 39/100\n",
      "581/581 [==============================] - 1s 2ms/step - loss: 0.2133\n",
      "Epoch 40/100\n",
      "581/581 [==============================] - 1s 2ms/step - loss: 0.2133\n",
      "Epoch 41/100\n",
      "581/581 [==============================] - 1s 2ms/step - loss: 0.2133\n",
      "Epoch 42/100\n",
      "581/581 [==============================] - 1s 2ms/step - loss: 0.2134\n",
      "Epoch 43/100\n",
      "581/581 [==============================] - 1s 2ms/step - loss: 0.2133\n",
      "Epoch 44/100\n",
      "581/581 [==============================] - 1s 2ms/step - loss: 0.2133\n",
      "Epoch 45/100\n",
      "581/581 [==============================] - 1s 2ms/step - loss: 0.2133\n",
      "Epoch 46/100\n",
      "581/581 [==============================] - 1s 2ms/step - loss: 0.2133\n",
      "Epoch 47/100\n",
      "581/581 [==============================] - 1s 2ms/step - loss: 0.2133\n",
      "Epoch 48/100\n",
      "581/581 [==============================] - 1s 1ms/step - loss: 0.2133\n",
      "Epoch 49/100\n",
      "581/581 [==============================] - 1s 2ms/step - loss: 0.2134\n",
      "Epoch 50/100\n",
      "581/581 [==============================] - 1s 2ms/step - loss: 0.2133\n",
      "Epoch 51/100\n",
      "581/581 [==============================] - 1s 2ms/step - loss: 0.2133\n",
      "Epoch 52/100\n",
      "581/581 [==============================] - 1s 2ms/step - loss: 0.2133\n",
      "Epoch 53/100\n",
      "581/581 [==============================] - 1s 2ms/step - loss: 0.2312\n",
      "Epoch 54/100\n",
      "581/581 [==============================] - 1s 1ms/step - loss: 0.2144\n",
      "Epoch 55/100\n",
      "581/581 [==============================] - 1s 2ms/step - loss: 0.2133\n",
      "Epoch 56/100\n",
      "581/581 [==============================] - 1s 1ms/step - loss: 0.2133\n",
      "Epoch 57/100\n",
      "581/581 [==============================] - 1s 1ms/step - loss: 0.2133\n",
      "Epoch 58/100\n",
      "581/581 [==============================] - 1s 1ms/step - loss: 0.2134\n",
      "Epoch 59/100\n",
      "581/581 [==============================] - 1s 2ms/step - loss: 0.2134\n",
      "Epoch 60/100\n",
      "581/581 [==============================] - 1s 2ms/step - loss: 0.2133\n",
      "Epoch 61/100\n",
      "581/581 [==============================] - 1s 2ms/step - loss: 0.2133\n",
      "Epoch 62/100\n",
      "581/581 [==============================] - 1s 2ms/step - loss: 0.2133\n",
      "Epoch 63/100\n",
      "581/581 [==============================] - 1s 1ms/step - loss: 0.2133\n",
      "Epoch 64/100\n",
      "581/581 [==============================] - 1s 1ms/step - loss: 0.2133\n",
      "Epoch 65/100\n",
      "581/581 [==============================] - 1s 1ms/step - loss: 0.2133\n",
      "Epoch 66/100\n",
      "581/581 [==============================] - 1s 1ms/step - loss: 0.2133\n",
      "Epoch 67/100\n",
      "581/581 [==============================] - 1s 1ms/step - loss: 0.2135\n",
      "Epoch 68/100\n",
      "581/581 [==============================] - 1s 1ms/step - loss: 0.2560\n",
      "Epoch 69/100\n",
      "581/581 [==============================] - 1s 1ms/step - loss: 0.2133\n",
      "Epoch 70/100\n",
      "581/581 [==============================] - 1s 1ms/step - loss: 0.2133\n",
      "Epoch 71/100\n",
      "581/581 [==============================] - 1s 2ms/step - loss: 0.2133\n",
      "Epoch 72/100\n",
      "581/581 [==============================] - 1s 1ms/step - loss: 0.2133\n",
      "Epoch 73/100\n",
      "581/581 [==============================] - 1s 1ms/step - loss: 0.2133\n",
      "Epoch 74/100\n",
      "581/581 [==============================] - 1s 2ms/step - loss: 0.2133\n",
      "Epoch 75/100\n",
      "581/581 [==============================] - 1s 1ms/step - loss: 0.2133\n",
      "Epoch 76/100\n",
      "581/581 [==============================] - 1s 1ms/step - loss: 0.2133\n",
      "Epoch 77/100\n",
      "581/581 [==============================] - 1s 1ms/step - loss: 0.2133\n",
      "Epoch 78/100\n",
      "581/581 [==============================] - 1s 1ms/step - loss: 0.2133\n",
      "Epoch 79/100\n",
      "581/581 [==============================] - 1s 1ms/step - loss: 0.2133\n",
      "Epoch 80/100\n",
      "581/581 [==============================] - 1s 1ms/step - loss: 0.2133\n",
      "Epoch 81/100\n",
      "581/581 [==============================] - 1s 1ms/step - loss: 0.2133\n",
      "Epoch 82/100\n",
      "581/581 [==============================] - 1s 1ms/step - loss: 0.2160\n",
      "Epoch 83/100\n",
      "581/581 [==============================] - 1s 1ms/step - loss: 0.2133\n",
      "Epoch 84/100\n",
      "581/581 [==============================] - 1s 1ms/step - loss: 0.2133\n",
      "Epoch 85/100\n",
      "581/581 [==============================] - 1s 2ms/step - loss: 0.2133\n",
      "Epoch 86/100\n",
      "581/581 [==============================] - 1s 2ms/step - loss: 0.2133\n",
      "Epoch 87/100\n",
      "581/581 [==============================] - 1s 1ms/step - loss: 0.2133\n",
      "Epoch 88/100\n",
      "581/581 [==============================] - 1s 1ms/step - loss: 0.2133\n",
      "Epoch 89/100\n",
      "581/581 [==============================] - 1s 1ms/step - loss: 0.2133\n",
      "Epoch 90/100\n",
      "581/581 [==============================] - 1s 1ms/step - loss: 0.2133\n",
      "Epoch 91/100\n",
      "581/581 [==============================] - 1s 1ms/step - loss: 0.2133\n",
      "Epoch 92/100\n",
      "581/581 [==============================] - 1s 2ms/step - loss: 0.2133\n",
      "Epoch 93/100\n",
      "581/581 [==============================] - 1s 1ms/step - loss: 0.2133\n",
      "Epoch 94/100\n",
      "581/581 [==============================] - 1s 1ms/step - loss: 0.2133\n",
      "Epoch 95/100\n",
      "581/581 [==============================] - 1s 1ms/step - loss: 0.2133\n",
      "Epoch 96/100\n",
      "581/581 [==============================] - 1s 1ms/step - loss: 0.2133\n",
      "Epoch 97/100\n",
      "581/581 [==============================] - 1s 1ms/step - loss: 0.2133\n",
      "Epoch 98/100\n",
      "581/581 [==============================] - 1s 1ms/step - loss: 0.2247\n",
      "Epoch 99/100\n",
      "581/581 [==============================] - 1s 1ms/step - loss: 0.2133\n",
      "Epoch 100/100\n",
      "581/581 [==============================] - 1s 1ms/step - loss: 0.2133\n",
      "581/581 [==============================] - 1s 732us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D, Dense, Flatten\n",
    "\n",
    "model = Sequential([\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(max_seq_length, 1)),\n",
    "    GlobalMaxPooling1D(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(150)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "model.fit(x_traincnn, y_traincnn, epochs=100, batch_size=32)\n",
    "\n",
    "embedding_layer_output = model.predict(x_traincnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "63a1fbbe-018d-47dd-a4cf-f4361b9bf0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194/194 [==============================] - 0s 753us/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nbcnn = GaussianNB()\n",
    "nbcnn.fit(embedding_layer_output,y_traincnn)\n",
    "\n",
    "y_predcnn= nbcnn.predict(model.predict(x_testcnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bf71846d-1132-40da-b89b-d4c456d3bc65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06020012911555842"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_testcnn,y_predcnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b25fe7a-9091-43af-b6fc-5aadd42b35a2",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ca02a9b3-94c0-48be-bab1-0f3dd833eadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "581/581 [==============================] - 55s 90ms/step - loss: 0.2657\n",
      "Epoch 2/10\n",
      "581/581 [==============================] - 51s 88ms/step - loss: 0.2259\n",
      "Epoch 3/10\n",
      "581/581 [==============================] - 51s 87ms/step - loss: 0.2256\n",
      "Epoch 4/10\n",
      "581/581 [==============================] - 49s 85ms/step - loss: 0.2256\n",
      "Epoch 5/10\n",
      "581/581 [==============================] - 49s 84ms/step - loss: 0.2255\n",
      "Epoch 6/10\n",
      "581/581 [==============================] - 49s 84ms/step - loss: 0.2255\n",
      "Epoch 7/10\n",
      "581/581 [==============================] - 49s 84ms/step - loss: 0.2255\n",
      "Epoch 8/10\n",
      "581/581 [==============================] - 49s 84ms/step - loss: 0.2255\n",
      "Epoch 9/10\n",
      "581/581 [==============================] - 49s 84ms/step - loss: 0.2255\n",
      "Epoch 10/10\n",
      "581/581 [==============================] - 49s 85ms/step - loss: 0.2255\n",
      "581/581 [==============================] - 6s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=150, input_length=max_seq_length),\n",
    "    LSTM(units=64) \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "model.fit(x_traincnn, y_traincnn, epochs=10, batch_size=32)\n",
    "\n",
    "embedding_layer_output = model.predict(x_traincnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "279f69eb-0048-40ae-8c0d-e92abb670540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194/194 [==============================] - 2s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nbrnn = GaussianNB()\n",
    "nbrnn.fit(embedding_layer_output,y_traincnn)\n",
    "\n",
    "y_predrnn= nbrnn.predict(model.predict(x_testcnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e6e47de3-6388-4d05-92cf-63a1611c07a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05842479018721756"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_testcnn,y_predrnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d6b1d3-0198-4410-8227-cba7858dcf3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
